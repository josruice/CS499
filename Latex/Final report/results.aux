\relax 
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{12}{section.6}}
\newlabel{sec:results}{{6}{12}{Results\relax }{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Parameter tuning}{12}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Graph showing the relation between the material recognition accuracy and the maximum number of \emph  {SIFT} descriptors per image, using 300 clusters and \emph  {SVMs} $\lambda =10^{-5}$. All these results were obtained using predicted data, i.e. the predicted material properties. In the case of the x-label \emph  {SIFT}, no maximum was forced.\relax }}{13}{figure.caption.12}}
\newlabel{fig:descriptorsTestedPred}{{11}{13}{Graph showing the relation between the material recognition accuracy and the maximum number of \emph {SIFT} descriptors per image, using 300 clusters and \emph {SVMs} $\lambda =10^{-5}$. All these results were obtained using predicted data, i.e. the predicted material properties. In the case of the x-label \emph {SIFT}, no maximum was forced.\relax \relax }{figure.caption.12}{}}
\newlabel{fig:descriptorsTestedPred@cref}{{[figure][11][]11}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Graph showing the relation between the material recognition accuracy and the maximum number of \emph  {SIFT} descriptors per image, using 300 clusters and \emph  {SVMs} $\lambda =10^{-5}$. All these results were obtained using real data, i.e. the material properties from the manual markup. In the case of the x-label \emph  {SIFT}, no maximum was forced.\relax }}{13}{figure.caption.13}}
\newlabel{fig:descriptorsTestedReal}{{12}{13}{Graph showing the relation between the material recognition accuracy and the maximum number of \emph {SIFT} descriptors per image, using 300 clusters and \emph {SVMs} $\lambda =10^{-5}$. All these results were obtained using real data, i.e. the material properties from the manual markup. In the case of the x-label \emph {SIFT}, no maximum was forced.\relax \relax }{figure.caption.13}{}}
\newlabel{fig:descriptorsTestedReal@cref}{{[figure][12][]12}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Graph showing the relation between the material recognition accuracy and the value of \emph  {SVMs} $\lambda $, using 300 clusters and non-dense \emph  {SIFT} without maximum descriptors limitation. All these results were obtained using predicted data, i.e. the predicted material properties.\relax }}{14}{figure.caption.14}}
\newlabel{fig:lambdaTestedPred}{{13}{14}{Graph showing the relation between the material recognition accuracy and the value of \emph {SVMs} $\lambda $, using 300 clusters and non-dense \emph {SIFT} without maximum descriptors limitation. All these results were obtained using predicted data, i.e. the predicted material properties.\relax \relax }{figure.caption.14}{}}
\newlabel{fig:lambdaTestedPred@cref}{{[figure][13][]13}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Graph showing the relation between the material recognition accuracy and the value of \emph  {SVMs} $\lambda $, using 300 clusters and non-dense \emph  {SIFT} without maximum descriptors limitation. All these results were obtained using real data, i.e. the material properties from the manual markup.\relax }}{14}{figure.caption.15}}
\newlabel{fig:lambdaTestedReal}{{14}{14}{Graph showing the relation between the material recognition accuracy and the value of \emph {SVMs} $\lambda $, using 300 clusters and non-dense \emph {SIFT} without maximum descriptors limitation. All these results were obtained using real data, i.e. the material properties from the manual markup.\relax \relax }{figure.caption.15}{}}
\newlabel{fig:lambdaTestedReal@cref}{{[figure][14][]14}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Graph showing the relation between the material recognition accuracy and the number of clusters in \emph  {k-means}, using \emph  {SVMs} $\lambda =10^{-5}$ and non-dense \emph  {SIFT} without maximum descriptors limitation. All these results were obtained using predicted data, i.e. the predicted material properties.\relax }}{15}{figure.caption.16}}
\newlabel{fig:numberOfClustersTestedPred}{{15}{15}{Graph showing the relation between the material recognition accuracy and the number of clusters in \emph {k-means}, using \emph {SVMs} $\lambda =10^{-5}$ and non-dense \emph {SIFT} without maximum descriptors limitation. All these results were obtained using predicted data, i.e. the predicted material properties.\relax \relax }{figure.caption.16}{}}
\newlabel{fig:numberOfClustersTestedPred@cref}{{[figure][15][]15}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Graph showing the relation between the material recognition accuracy and the number of clusters in \emph  {k-means}, using \emph  {SVMs} $\lambda =10^{-5}$ and non-dense \emph  {SIFT} without maximum descriptors limitation. All these results were obtained using real data, i.e. the material properties from the manual markup.\relax }}{15}{figure.caption.17}}
\newlabel{fig:numberOfClustersTestedReal}{{16}{15}{Graph showing the relation between the material recognition accuracy and the number of clusters in \emph {k-means}, using \emph {SVMs} $\lambda =10^{-5}$ and non-dense \emph {SIFT} without maximum descriptors limitation. All these results were obtained using real data, i.e. the material properties from the manual markup.\relax \relax }{figure.caption.17}{}}
\newlabel{fig:numberOfClustersTestedReal@cref}{{[figure][16][]16}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Properties recognition accuracy}{16}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Bar chart showing the global accuracy in the detection of a property or the lack of it, sorted by \emph  {scale-property}. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{17}{figure.caption.18}}
\newlabel{fig:globalAccuracy3}{{17}{17}{Bar chart showing the global accuracy in the detection of a property or the lack of it, sorted by \emph {scale-property}. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.18}{}}
\newlabel{fig:globalAccuracy3@cref}{{[figure][17][]17}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Bar chart showing the global accuracy in the detection of a property or the lack of it, sorted by the accuracy itself. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{17}{figure.caption.19}}
\newlabel{fig:globalAccuracySorted3}{{18}{17}{Bar chart showing the global accuracy in the detection of a property or the lack of it, sorted by the accuracy itself. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.19}{}}
\newlabel{fig:globalAccuracySorted3@cref}{{[figure][18][]18}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Bar chart showing the \emph  {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by \emph  {scale-property}. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{18}{figure.caption.20}}
\newlabel{fig:precision3}{{19}{18}{Bar chart showing the \emph {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by \emph {scale-property}. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.20}{}}
\newlabel{fig:precision3@cref}{{[figure][19][]19}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Bar chart showing the \emph  {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by the \emph  {precision} itself. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{18}{figure.caption.21}}
\newlabel{fig:precisionSorted3}{{20}{18}{Bar chart showing the \emph {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by the \emph {precision} itself. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.21}{}}
\newlabel{fig:precisionSorted3@cref}{{[figure][20][]20}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Bar chart showing the \emph  {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by \emph  {scale-property}. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{19}{figure.caption.22}}
\newlabel{fig:recall3}{{21}{19}{Bar chart showing the \emph {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by \emph {scale-property}. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.22}{}}
\newlabel{fig:recall3@cref}{{[figure][21][]21}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Bar chart showing the \emph  {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by the \emph  {recall} itself. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{19}{figure.caption.23}}
\newlabel{fig:recallSorted3}{{22}{19}{Bar chart showing the \emph {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by the \emph {recall} itself. The test set was composed of the first image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.23}{}}
\newlabel{fig:recallSorted3@cref}{{[figure][22][]22}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Bar chart showing the global accuracy in the detection of a property or the lack of ifig:t, sorted by \emph  {scale-property}. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{20}{figure.caption.24}}
\newlabel{fig:globalAccuracy4}{{23}{20}{Bar chart showing the global accuracy in the detection of a property or the lack of ifig:t, sorted by \emph {scale-property}. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.24}{}}
\newlabel{fig:globalAccuracy4@cref}{{[figure][23][]23}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Bar chart showing the global accuracy in the detection of a property or the lack of ifig:t, sorted by the accuracy itself. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{20}{figure.caption.25}}
\newlabel{fig:globalAccuracySorted4}{{24}{20}{Bar chart showing the global accuracy in the detection of a property or the lack of ifig:t, sorted by the accuracy itself. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.25}{}}
\newlabel{fig:globalAccuracySorted4@cref}{{[figure][24][]24}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Bar chart showing the \emph  {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by \emph  {scale-property}. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{21}{figure.caption.26}}
\newlabel{fig:precision4}{{25}{21}{Bar chart showing the \emph {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by \emph {scale-property}. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.26}{}}
\newlabel{fig:precision4@cref}{{[figure][25][]25}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Bar chart showing the \emph  {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by the \emph  {precision} itself. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{21}{figure.caption.27}}
\newlabel{fig:precisionSorted4}{{26}{21}{Bar chart showing the \emph {precision} in the detection of a property, i.e. the number of true positives over the total number of image samples that has been classified as having the property, sorted by the \emph {precision} itself. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.27}{}}
\newlabel{fig:precisionSorted4@cref}{{[figure][26][]26}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Bar chart showing the \emph  {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by \emph  {scale-property}. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{22}{figure.caption.28}}
\newlabel{fig:recall4}{{27}{22}{Bar chart showing the \emph {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by \emph {scale-property}. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.28}{}}
\newlabel{fig:recall4@cref}{{[figure][27][]27}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Bar chart showing the \emph  {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by the \emph  {recall} itself. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$.\relax }}{22}{figure.caption.29}}
\newlabel{fig:recallSorted4}{{28}{22}{Bar chart showing the \emph {recall} in the detection of a property, i.e. the number of true positives over the total number of image samples with the property, sorted by the \emph {recall} itself. The test set was composed of the second image of each material class, while the rest of the images were part of the training set. Measurements obtained using dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$.\relax \relax }{figure.caption.29}{}}
\newlabel{fig:recallSorted4@cref}{{[figure][28][]28}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Confusion matrices}{23}{subsection.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {SVMs} trained with predicted data, i.e., properties estimated algorithmically, and tested also with predicted data. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 45.37 \%, with 98 out of 216 correctly classified.\relax }}{24}{figure.caption.30}}
\newlabel{fig:svmPredPred}{{29}{24}{Heat map representing the confusion matrix of the material recognition process using \emph {SVMs} trained with predicted data, i.e., properties estimated algorithmically, and tested also with predicted data. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 45.37 \%, with 98 out of 216 correctly classified.\relax \relax }{figure.caption.30}{}}
\newlabel{fig:svmPredPred@cref}{{[figure][29][]29}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {SVMs} trained with predicted data, i.e., properties estimated algorithmically, and tested with real data, i.e., properties extracted from the manual markup. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 80.56 \%, with 174 out of 216 correctly classified.\relax }}{25}{figure.caption.31}}
\newlabel{fig:svmPredReal}{{30}{25}{Heat map representing the confusion matrix of the material recognition process using \emph {SVMs} trained with predicted data, i.e., properties estimated algorithmically, and tested with real data, i.e., properties extracted from the manual markup. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 80.56 \%, with 174 out of 216 correctly classified.\relax \relax }{figure.caption.31}{}}
\newlabel{fig:svmPredReal@cref}{{[figure][30][]30}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {SVMs} trained with real data, i.e., properties extracted from the manual markup, and tested with predicted data, i.e., properties estimated algorithmically. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 46.30 \%, with 100 out of 216 correctly classified.\relax }}{26}{figure.caption.32}}
\newlabel{fig:svmRealPred}{{31}{26}{Heat map representing the confusion matrix of the material recognition process using \emph {SVMs} trained with real data, i.e., properties extracted from the manual markup, and tested with predicted data, i.e., properties estimated algorithmically. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 46.30 \%, with 100 out of 216 correctly classified.\relax \relax }{figure.caption.32}{}}
\newlabel{fig:svmRealPred@cref}{{[figure][31][]31}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {SVMs} trained with real data, i.e., properties extracted from the manual markup, and tested also with predicted data. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 79.63 \%, with 172 out of 216 correctly classified.\relax }}{27}{figure.caption.33}}
\newlabel{fig:svmRealReal}{{32}{27}{Heat map representing the confusion matrix of the material recognition process using \emph {SVMs} trained with real data, i.e., properties extracted from the manual markup, and tested also with predicted data. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 79.63 \%, with 172 out of 216 correctly classified.\relax \relax }{figure.caption.33}{}}
\newlabel{fig:svmRealReal@cref}{{[figure][32][]32}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {Naive Bayes} trained with predicted data, i.e., properties estimated algorithmically, and tested also with predicted data. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 44.44 \%, with 96 out of 216 correctly classified.\relax }}{28}{figure.caption.34}}
\newlabel{fig:nbPredPred}{{33}{28}{Heat map representing the confusion matrix of the material recognition process using \emph {Naive Bayes} trained with predicted data, i.e., properties estimated algorithmically, and tested also with predicted data. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 44.44 \%, with 96 out of 216 correctly classified.\relax \relax }{figure.caption.34}{}}
\newlabel{fig:nbPredPred@cref}{{[figure][33][]33}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {Naive Bayes} trained with predicted data, i.e., properties estimated algorithmically, and tested with real data, i.e., properties extracted from the manual markup. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 81.02 \%, with 175 out of 216 correctly classified.\relax }}{29}{figure.caption.35}}
\newlabel{fig:nbPredReal}{{34}{29}{Heat map representing the confusion matrix of the material recognition process using \emph {Naive Bayes} trained with predicted data, i.e., properties estimated algorithmically, and tested with real data, i.e., properties extracted from the manual markup. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 81.02 \%, with 175 out of 216 correctly classified.\relax \relax }{figure.caption.35}{}}
\newlabel{fig:nbPredReal@cref}{{[figure][34][]34}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {Naive Bayes} trained with real data, i.e., properties extracted from the manual markup, and tested with predicted data, i.e., properties estimated algorithmically. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 44.44 \%, with 96 out of 216 correctly classified.\relax }}{30}{figure.caption.36}}
\newlabel{fig:nbRealPred}{{35}{30}{Heat map representing the confusion matrix of the material recognition process using \emph {Naive Bayes} trained with real data, i.e., properties extracted from the manual markup, and tested with predicted data, i.e., properties estimated algorithmically. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 44.44 \%, with 96 out of 216 correctly classified.\relax \relax }{figure.caption.36}{}}
\newlabel{fig:nbRealPred@cref}{{[figure][35][]35}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Heat map representing the confusion matrix of the material recognition process using \emph  {Naive Bayes} trained with real data, i.e., properties extracted from the manual markup, and tested also with predicted data. The results are the average of a \emph  {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph  {SIFT} (\emph  {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph  {SVM} $\lambda =10^{-3}$. The average precision obtained is 82.41 \%, with 178 out of 216 correctly classified.\relax }}{31}{figure.caption.37}}
\newlabel{fig:nbRealReal}{{36}{31}{Heat map representing the confusion matrix of the material recognition process using \emph {Naive Bayes} trained with real data, i.e., properties extracted from the manual markup, and tested also with predicted data. The results are the average of a \emph {cross-validation} process of 12 partitions, where the test set had at least one sample of each class. The parameters used are dense \emph {SIFT} (\emph {PHOW}) limited to a maximum of 2000 descriptors per image, with 600 clusters and \emph {SVM} $\lambda =10^{-3}$. The average precision obtained is 82.41 \%, with 178 out of 216 correctly classified.\relax \relax }{figure.caption.37}{}}
\newlabel{fig:nbRealReal@cref}{{[figure][36][]36}{31}}
\@setckpt{results}{
\setcounter{page}{32}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{section}{6}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{36}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{cp@cnt}{0}
\setcounter{cp@tempcnt}{0}
\setcounter{float@type}{8}
\setcounter{SC@C}{0}
\setcounter{Item}{22}
\setcounter{Hfootnote}{2}
\setcounter{bookmark@seq@number}{21}
\setcounter{lstnumber}{1}
\setcounter{ContinuedFloat}{0}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
